{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5689bd4-269f-449e-978b-d2465452b974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPREHENSIVE DATA EXPLORATION REPORT\n",
      "================================================================================\n",
      "Analyzing: olist_customers_dataset.csv\n",
      "============================================================\n",
      "Columns (5): ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
      "Sample size: 1000 rows\n",
      "\n",
      "Column Analysis:\n",
      "  customer_id:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['36b735afba701eeba82799b7d22161b2', '57934d36535621517dc2b60295108836', 'db2cf3b3feeca251d6c3c93bf5f1b75a']\n",
      "  customer_unique_id:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 999\n",
      "    Sample values: ['d647ac91ff870deee189d7cd0cbf2380', '4f6d635ff2fd4e30ff5369a7b943eb22', '8c2a5c47e0c02478c440038904724cd5']\n",
      "  customer_zip_code_prefix:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 935\n",
      "    Sample values: ['65075', '04427', '30380']\n",
      "  customer_city:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 379\n",
      "    Sample values: ['ibia', 'ibatiba', 'valenca']\n",
      "  customer_state:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 26\n",
      "    Sample values: ['ES', 'PI', 'SE']\n",
      "\n",
      "Business Column Identification:\n",
      "  ID columns: ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix']\n",
      "  Customer: ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
      "  Location: ['customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
      "\n",
      "Data Quality Assessment:\n",
      "  Overall completeness: 100.0%\n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "  Row 1: {'customer_id': '06b8999e2fba1a1fbc88172c00ba8bc7', 'customer_unique_id': '861eff4711a542e4b93843c6dd7febb0', 'customer_zip_code_prefix': '14409', 'customer_city': 'franca', 'customer_state': 'SP'}\n",
      "  Row 2: {'customer_id': '18955e83d337fd6b2def6b18a428ac77', 'customer_unique_id': '290c77bc529b7ac935b93aa66c333dc3', 'customer_zip_code_prefix': '09790', 'customer_city': 'sao bernardo do campo', 'customer_state': 'SP'}\n",
      "  Row 3: {'customer_id': '4e7b3e00288586ebd08712fdd0374a03', 'customer_unique_id': '060e732b5b29e8181a18229c7b0b2b5e', 'customer_zip_code_prefix': '01151', 'customer_city': 'sao paulo', 'customer_state': 'SP'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Analyzing: olist_products_dataset.csv\n",
      "============================================================\n",
      "Columns (9): ['product_id', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
      "Sample size: 1000 rows\n",
      "\n",
      "Column Analysis:\n",
      "  product_id:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['8ba4f2a4ae695d26e5626c1bf710975e', '8fec581a22f1e87d7e0f0a0da4626a82', '73c15f15e628e4ec389e0ed1cec48b15']\n",
      "  product_category_name:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 29 (2.9%)\n",
      "    Unique values: 58\n",
      "    Sample values: ['instrumentos_musicais', 'automotivo', 'pcs']\n",
      "  product_name_lenght:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 29 (2.9%)\n",
      "    Unique values: 51\n",
      "    Sample values: ['62', '43', '44']\n",
      "  product_description_lenght:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 29 (2.9%)\n",
      "    Unique values: 698\n",
      "    Sample values: ['805', '273', '282']\n",
      "  product_photos_qty:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 29 (2.9%)\n",
      "    Unique values: 13\n",
      "    Sample values: ['1', '2', '17']\n",
      "  product_weight_g:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 282\n",
      "    Sample values: ['6050', '3350', '18200']\n",
      "  product_length_cm:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 70\n",
      "    Sample values: ['62', '43', '17']\n",
      "  product_height_cm:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 64\n",
      "    Sample values: ['43', '17', '13']\n",
      "  product_width_cm:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 56\n",
      "    Sample values: ['43', '44', '13']\n",
      "\n",
      "Business Column Identification:\n",
      "  ID columns: ['product_id', 'product_width_cm']\n",
      "  Product: ['product_id', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
      "  Category: ['product_category_name']\n",
      "\n",
      "Data Quality Assessment:\n",
      "  Overall completeness: 98.7%\n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "  Row 1: {'product_id': '1e9e8ef04dbcff4541ed26657ea517e5', 'product_category_name': 'perfumaria', 'product_name_lenght': '40', 'product_description_lenght': '287', 'product_photos_qty': '1', 'product_weight_g': '225', 'product_length_cm': '16', 'product_height_cm': '10', 'product_width_cm': '14'}\n",
      "  Row 2: {'product_id': '3aa071139cb16b67ca9e5dea641aaa2f', 'product_category_name': 'artes', 'product_name_lenght': '44', 'product_description_lenght': '276', 'product_photos_qty': '1', 'product_weight_g': '1000', 'product_length_cm': '30', 'product_height_cm': '18', 'product_width_cm': '20'}\n",
      "  Row 3: {'product_id': '96bd76ec8810374ed1b65e291975717f', 'product_category_name': 'esporte_lazer', 'product_name_lenght': '46', 'product_description_lenght': '250', 'product_photos_qty': '1', 'product_weight_g': '154', 'product_length_cm': '18', 'product_height_cm': '9', 'product_width_cm': '15'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Analyzing: olist_orders_dataset.csv\n",
      "============================================================\n",
      "Columns (8): ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "Sample size: 1000 rows\n",
      "\n",
      "Column Analysis:\n",
      "  order_id:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['eb1873ec4d6a2af1c0626a7d08bd9c09', 'aa2e81559d88cca16ac122e7627078c8', '0b50bea7ba1e8ba7a21b01b7c9d1350b']\n",
      "  customer_id:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['66a1ad480e947477de23aa06e861feb9', '7df71d1652cfba8b2a70cf665c960f74', 'eb3203704b8613482fed4eb17ea5d66a']\n",
      "  order_status:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 6\n",
      "    Top values: {'delivered': 975, 'shipped': 13, 'unavailable': 4}\n",
      "  order_purchase_timestamp:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['2018-06-16 00:01:56', '2018-06-24 19:01:52', '2017-06-13 11:13:38']\n",
      "  order_approved_at:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['2018-01-31 14:23:50', '2018-02-01 17:33:10', '2017-12-07 03:12:20']\n",
      "  order_delivered_carrier_date:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 11 (1.1%)\n",
      "    Unique values: 985\n",
      "    Sample values: ['2017-10-04 16:50:10', '2018-01-12 00:35:33', '2018-07-03 10:48:00']\n",
      "  order_delivered_customer_date:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 25 (2.5%)\n",
      "    Unique values: 975\n",
      "    Sample values: ['2018-07-05 22:52:28', '2018-01-23 21:45:13', '2018-03-09 21:52:36']\n",
      "  order_estimated_delivery_date:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 349\n",
      "    Sample values: ['2018-07-13 00:00:00', '2017-10-18 00:00:00', '2017-10-11 00:00:00']\n",
      "\n",
      "Business Column Identification:\n",
      "  ID columns: ['order_id', 'customer_id']\n",
      "  Customer: ['customer_id', 'order_delivered_customer_date']\n",
      "  Date/Time: ['order_purchase_timestamp', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "\n",
      "Data Quality Assessment:\n",
      "  Overall completeness: 99.5%\n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "  Row 1: {'order_id': 'e481f51cbdc54678b7cc49136f2d6af7', 'customer_id': '9ef432eb6251297304e76186b10a928d', 'order_status': 'delivered', 'order_purchase_timestamp': '2017-10-02 10:56:33', 'order_approved_at': '2017-10-02 11:07:15', 'order_delivered_carrier_date': '2017-10-04 19:55:00', 'order_delivered_customer_date': '2017-10-10 21:25:13', 'order_estimated_delivery_date': '2017-10-18 00:00:00'}\n",
      "  Row 2: {'order_id': '53cdb2fc8bc7dce0b6741e2150273451', 'customer_id': 'b0830fb4747a6c6d20dea0b8c802d7ef', 'order_status': 'delivered', 'order_purchase_timestamp': '2018-07-24 20:41:37', 'order_approved_at': '2018-07-26 03:24:27', 'order_delivered_carrier_date': '2018-07-26 14:31:00', 'order_delivered_customer_date': '2018-08-07 15:27:45', 'order_estimated_delivery_date': '2018-08-13 00:00:00'}\n",
      "  Row 3: {'order_id': '47770eb9100c2d0c44946d9cf07ec65d', 'customer_id': '41ce2a54c0b03bf3443c3d931a367089', 'order_status': 'delivered', 'order_purchase_timestamp': '2018-08-08 08:38:49', 'order_approved_at': '2018-08-08 08:55:23', 'order_delivered_carrier_date': '2018-08-08 13:50:00', 'order_delivered_customer_date': '2018-08-17 18:06:29', 'order_estimated_delivery_date': '2018-09-04 00:00:00'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Analyzing: olist_order_items_dataset.csv\n",
      "============================================================\n",
      "Columns (7): ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n",
      "Sample size: 1000 rows\n",
      "\n",
      "Column Analysis:\n",
      "  order_id:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 877\n",
      "    Sample values: ['016754282c7690ebd6658f9f8e0a49bb', '00c8be06a8029e300dabd52c7d4c6ad2', '0066a1fdaee16ad5022c5ef979d0b661']\n",
      "  order_item_id:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 5\n",
      "    Top values: {'1': 877, '2': 94, '3': 20}\n",
      "  product_id:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 832\n",
      "    Sample values: ['d1c427060a0f73f6b889a5c7c61f2ac4', '735413ccfa564132a231aad945ef85ad', '9bde344a67494559d37249506076d638']\n",
      "  seller_id:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 456\n",
      "    Sample values: ['5bc55dbe2f12b6af6d83ed46023e0dc8', '11bfa66332777660bd0640ee84d47006', '1b938a7ec6ac5061a66a3766e0e75f90']\n",
      "  shipping_limit_date:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 877\n",
      "    Sample values: ['2017-04-24 22:25:19', '2018-01-26 14:16:49', '2017-12-07 11:17:32']\n",
      "  price:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 470\n",
      "    Sample values: ['219.90', '211.05', '25.79']\n",
      "  freight_value:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 593\n",
      "    Sample values: ['19.88', '19.98', '8.77']\n",
      "\n",
      "Business Column Identification:\n",
      "  ID columns: ['order_id', 'order_item_id', 'product_id', 'seller_id']\n",
      "  Product: ['order_item_id', 'product_id']\n",
      "  Date/Time: ['shipping_limit_date']\n",
      "  Price/Amount: ['price', 'freight_value']\n",
      "\n",
      "Data Quality Assessment:\n",
      "  Overall completeness: 100.0%\n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "  Row 1: {'order_id': '00010242fe8c5a6d1ba2dd792cb16214', 'order_item_id': '1', 'product_id': '4244733e06e7ecb4970a6e2683c13e61', 'seller_id': '48436dade18ac8b2bce089ec2a041202', 'shipping_limit_date': '2017-09-19 09:45:35', 'price': '58.90', 'freight_value': '13.29'}\n",
      "  Row 2: {'order_id': '00018f77f2f0320c557190d7a144bdd3', 'order_item_id': '1', 'product_id': 'e5f2d52b802189ee658865ca93d83a8f', 'seller_id': 'dd7ddc04e1b6c2c614352b383efe2d36', 'shipping_limit_date': '2017-05-03 11:05:13', 'price': '239.90', 'freight_value': '19.93'}\n",
      "  Row 3: {'order_id': '000229ec398224ef6ca0657da4fc703e', 'order_item_id': '1', 'product_id': 'c777355d18b72b67abbeef9df44fd0fd', 'seller_id': '5b51032eddd242adc84c38acab88f23d', 'shipping_limit_date': '2018-01-18 14:48:30', 'price': '199.00', 'freight_value': '17.87'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Analyzing: olist_order_payments_dataset.csv\n",
      "============================================================\n",
      "Columns (5): ['order_id', 'payment_sequential', 'payment_type', 'payment_installments', 'payment_value']\n",
      "Sample size: 1000 rows\n",
      "\n",
      "Column Analysis:\n",
      "  order_id:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['4cc95216e51190048472a2baf6fa53ee', '60bcba6747ee878b9007f61275f4cd1f', '69ab7fdbd887d055b05826a8cc5591d7']\n",
      "  payment_sequential:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 7\n",
      "    Top values: {'1': 954, '2': 35, '5': 4}\n",
      "  payment_type:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 4\n",
      "    Top values: {'credit_card': 735, 'boleto': 186, 'voucher': 57}\n",
      "  payment_installments:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 12\n",
      "    Sample values: ['2', '13', '9']\n",
      "  payment_value:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 936\n",
      "    Sample values: ['265.41', '180.47', '341.09']\n",
      "\n",
      "Business Column Identification:\n",
      "  ID columns: ['order_id']\n",
      "  Category: ['payment_type']\n",
      "  Price/Amount: ['payment_value']\n",
      "\n",
      "Data Quality Assessment:\n",
      "  Overall completeness: 100.0%\n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "  Row 1: {'order_id': 'b81ef226f3fe1789b1e8b2acac839d17', 'payment_sequential': '1', 'payment_type': 'credit_card', 'payment_installments': '8', 'payment_value': '99.33'}\n",
      "  Row 2: {'order_id': 'a9810da82917af2d9aefd1278f1dcfa0', 'payment_sequential': '1', 'payment_type': 'credit_card', 'payment_installments': '1', 'payment_value': '24.39'}\n",
      "  Row 3: {'order_id': '25e8ea4e93396b6fa0d3dd708e76c1bd', 'payment_sequential': '1', 'payment_type': 'credit_card', 'payment_installments': '1', 'payment_value': '65.71'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Analyzing: olist_order_reviews_dataset.csv\n",
      "============================================================\n",
      "Columns (7): ['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
      "Sample size: 1000 rows\n",
      "\n",
      "Column Analysis:\n",
      "  review_id:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['f5341e7a7371be7c0730ccb38420f662', 'c239d18d7e310e477d5e7b76b362db1d', 'd10aa47a4914ed4e55ee13dc41198aa6']\n",
      "  order_id:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['44a9994228432b835c3a4e720b6a41ab', 'adad66be45caa015d25e03ed17610197', '043f43899c67438005004d160d18f55c']\n",
      "  review_score:\n",
      "    Type: Categorical (Low cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 5\n",
      "    Top values: {'5': 579, '4': 174, '1': 125}\n",
      "  review_comment_title:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 885 (88.5%)\n",
      "    Unique values: 90\n",
      "    Sample values: ['Ótima compra', 'Muito bom.', 'Médio']\n",
      "  review_comment_message:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 564 (56.4%)\n",
      "    Unique values: 432\n",
      "    Sample values: ['prazo foi estendido,porém entregue no prazo divulgado na propaganda. Cadeira conforme foto, vem para montar, mais fácil e linda', 'Excelente produto indico a qualquer pessoa.', 'Recomendo o vendedor...']\n",
      "  review_creation_date:\n",
      "    Type: Text (Medium cardinality)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 404\n",
      "    Sample values: ['2018-07-13 00:00:00', '2017-11-02 00:00:00', '2017-10-11 00:00:00']\n",
      "  review_answer_timestamp:\n",
      "    Type: Text (High cardinality/ID)\n",
      "    Missing: 0 (0.0%)\n",
      "    Unique values: 1000\n",
      "    Sample values: ['2018-01-31 23:29:21', '2018-05-10 07:37:59', '2018-05-21 10:31:58']\n",
      "\n",
      "Business Column Identification:\n",
      "  ID columns: ['review_id', 'order_id']\n",
      "  Rating/Score: ['review_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
      "  Date/Time: ['review_creation_date', 'review_answer_timestamp']\n",
      "\n",
      "Data Quality Assessment:\n",
      "  Overall completeness: 79.3%\n",
      "  High missing (>50%): ['review_comment_title', 'review_comment_message']\n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "  Row 1: {'review_id': '7bc2406110b926393aa56f80a40eba40', 'order_id': '73fc7af87114b39712e6da79b0a377eb', 'review_score': '4', 'review_comment_title': '', 'review_comment_message': '', 'review_creation_date': '2018-01-18 00:00:00', 'review_answer_timestamp': '2018-01-18 21:46:59'}\n",
      "  Row 2: {'review_id': '80e641a11e56f04c1ad469d5645fdfde', 'order_id': 'a548910a1c6147796b98fdf73dbeba33', 'review_score': '5', 'review_comment_title': '', 'review_comment_message': '', 'review_creation_date': '2018-03-10 00:00:00', 'review_answer_timestamp': '2018-03-11 03:05:13'}\n",
      "  Row 3: {'review_id': '228ce5500dc1d8e020d8d1322874b6f0', 'order_id': 'f9e4b658b201a9f2ecdecbb34bed034b', 'review_score': '5', 'review_comment_title': '', 'review_comment_message': '', 'review_creation_date': '2018-02-17 00:00:00', 'review_answer_timestamp': '2018-02-18 14:36:24'}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "CROSS-DATASET SUMMARY\n",
      "==================================================\n",
      "Dataset Overview:\n",
      "  olist_customers_dataset.csv: (1000, 5) - 100.0% complete\n",
      "  olist_products_dataset.csv: (1000, 9) - 98.7% complete\n",
      "  olist_orders_dataset.csv: (1000, 8) - 99.5% complete\n",
      "  olist_order_items_dataset.csv: (1000, 7) - 100.0% complete\n",
      "  olist_order_payments_dataset.csv: (1000, 5) - 100.0% complete\n",
      "  olist_order_reviews_dataset.csv: (1000, 7) - 79.3% complete\n",
      "\n",
      "Common columns across datasets:\n",
      "  customer_id: ['olist_customers_dataset.csv', 'olist_orders_dataset.csv']\n",
      "  product_id: ['olist_products_dataset.csv', 'olist_order_items_dataset.csv']\n",
      "  order_id: ['olist_orders_dataset.csv', 'olist_order_items_dataset.csv', 'olist_order_payments_dataset.csv', 'olist_order_reviews_dataset.csv']\n",
      "\n",
      "Business Use Case Assessment:\n",
      "\n",
      "Sales Forecasting:\n",
      "  olist_order_items_dataset.csv: 3/6 keyword matches\n",
      "  olist_orders_dataset.csv: 2/6 keyword matches\n",
      "  olist_order_reviews_dataset.csv: 2/6 keyword matches\n",
      "\n",
      "Customer Analysis:\n",
      "  olist_orders_dataset.csv: 3/5 keyword matches\n",
      "\n",
      "Product Analytics:\n",
      "  olist_order_items_dataset.csv: 3/5 keyword matches\n",
      "  olist_products_dataset.csv: 2/5 keyword matches\n",
      "\n",
      "Transaction Analysis:\n",
      "  olist_orders_dataset.csv: 3/5 keyword matches\n",
      "  olist_order_items_dataset.csv: 2/5 keyword matches\n",
      "  olist_order_payments_dataset.csv: 2/5 keyword matches\n",
      "  olist_order_reviews_dataset.csv: 2/5 keyword matches\n",
      "\n",
      "Next Steps Recommendations:\n",
      "1. Focus on datasets with >80% completeness for initial development\n",
      "2. Plan data joining strategy using common columns\n",
      "3. Prioritize use cases based on data availability\n",
      "4. Design cleaning pipeline for identified quality issues\n"
     ]
    }
   ],
   "source": [
    "# Enhanced CSV exploration without pandas\n",
    "import os\n",
    "import csv\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def comprehensive_csv_analysis(file_path, sample_size=1000):\n",
    "    \"\"\"Comprehensive CSV analysis without pandas\"\"\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Analyzing: {os.path.basename(file_path)}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        \n",
    "        # Get headers\n",
    "        headers = next(reader)\n",
    "        num_cols = len(headers)\n",
    "        print(f\"Columns ({num_cols}): {headers}\")\n",
    "        \n",
    "        # Read sample data\n",
    "        rows = []\n",
    "        for i, row in enumerate(reader):\n",
    "            if i >= sample_size:\n",
    "                break\n",
    "            rows.append(row)\n",
    "        \n",
    "        total_rows = len(rows)\n",
    "        print(f\"Sample size: {total_rows} rows\")\n",
    "        \n",
    "        # Basic statistics per column\n",
    "        print(\"\\nColumn Analysis:\")\n",
    "        column_stats = {}\n",
    "        \n",
    "        for col_idx, col_name in enumerate(headers):\n",
    "            values = []\n",
    "            missing_count = 0\n",
    "            \n",
    "            for row in rows:\n",
    "                if col_idx < len(row) and row[col_idx].strip():\n",
    "                    values.append(row[col_idx].strip())\n",
    "                else:\n",
    "                    missing_count += 1\n",
    "            \n",
    "            # Determine column type and statistics\n",
    "            non_missing = len(values)\n",
    "            missing_pct = (missing_count / total_rows) * 100\n",
    "            \n",
    "            # Try to detect data type\n",
    "            numeric_count = 0\n",
    "            date_like_count = 0\n",
    "            unique_values = set(values)\n",
    "            \n",
    "            for val in values[:100]:  # Sample first 100 values\n",
    "                # Check if numeric\n",
    "                try:\n",
    "                    float(val.replace(',', '').replace('$', ''))\n",
    "                    numeric_count += 1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Check if date-like\n",
    "                if any(sep in val for sep in ['-', '/', ' ']) and any(char.isdigit() for char in val):\n",
    "                    date_like_count += 1\n",
    "            \n",
    "            # Classify column type\n",
    "            if numeric_count > len(values) * 0.8:\n",
    "                col_type = \"Numeric\"\n",
    "            elif date_like_count > len(values) * 0.5:\n",
    "                col_type = \"Date-like\"\n",
    "            elif len(unique_values) < non_missing * 0.1:\n",
    "                col_type = \"Categorical (Low cardinality)\"\n",
    "            elif len(unique_values) > non_missing * 0.9:\n",
    "                col_type = \"Text (High cardinality/ID)\"\n",
    "            else:\n",
    "                col_type = \"Text (Medium cardinality)\"\n",
    "            \n",
    "            column_stats[col_name] = {\n",
    "                'type': col_type,\n",
    "                'missing_count': missing_count,\n",
    "                'missing_pct': missing_pct,\n",
    "                'unique_values': len(unique_values),\n",
    "                'sample_values': list(unique_values)[:5]\n",
    "            }\n",
    "            \n",
    "            print(f\"  {col_name}:\")\n",
    "            print(f\"    Type: {col_type}\")\n",
    "            print(f\"    Missing: {missing_count} ({missing_pct:.1f}%)\")\n",
    "            print(f\"    Unique values: {len(unique_values)}\")\n",
    "            if col_type.startswith(\"Categorical\") and len(unique_values) <= 10:\n",
    "                value_counts = Counter(values)\n",
    "                print(f\"    Top values: {dict(value_counts.most_common(3))}\")\n",
    "            elif len(unique_values) <= 5:\n",
    "                print(f\"    All values: {list(unique_values)}\")\n",
    "            else:\n",
    "                print(f\"    Sample values: {list(unique_values)[:3]}\")\n",
    "        \n",
    "        # Business column identification\n",
    "        print(\"\\nBusiness Column Identification:\")\n",
    "        business_patterns = {\n",
    "            'ID columns': ['id', 'key', 'identifier', 'code'],\n",
    "            'Price/Amount': ['price', 'cost', 'amount', 'value', 'total', 'revenue'],\n",
    "            'Date/Time': ['date', 'time', 'created', 'updated', 'timestamp'],\n",
    "            'Category': ['category', 'type', 'class', 'group', 'segment'],\n",
    "            'Rating/Score': ['rating', 'score', 'stars', 'review'],\n",
    "            'Location': ['city', 'state', 'country', 'address', 'location', 'zip'],\n",
    "            'Customer': ['customer', 'user', 'client', 'buyer'],\n",
    "            'Product': ['product', 'item', 'sku', 'goods']\n",
    "        }\n",
    "        \n",
    "        identified_cols = defaultdict(list)\n",
    "        for col in headers:\n",
    "            col_lower = col.lower()\n",
    "            for pattern_type, keywords in business_patterns.items():\n",
    "                if any(keyword in col_lower for keyword in keywords):\n",
    "                    identified_cols[pattern_type].append(col)\n",
    "        \n",
    "        for pattern_type, cols in identified_cols.items():\n",
    "            if cols:\n",
    "                print(f\"  {pattern_type}: {cols}\")\n",
    "        \n",
    "        # Data quality assessment\n",
    "        print(\"\\nData Quality Assessment:\")\n",
    "        high_missing = [col for col, stats in column_stats.items() if stats['missing_pct'] > 50]\n",
    "        moderate_missing = [col for col, stats in column_stats.items() if 10 < stats['missing_pct'] <= 50]\n",
    "        \n",
    "        overall_completeness = 100 - (sum(stats['missing_count'] for stats in column_stats.values()) / (total_rows * num_cols) * 100)\n",
    "        \n",
    "        print(f\"  Overall completeness: {overall_completeness:.1f}%\")\n",
    "        if high_missing:\n",
    "            print(f\"  High missing (>50%): {high_missing}\")\n",
    "        if moderate_missing:\n",
    "            print(f\"  Moderate missing (10-50%): {moderate_missing}\")\n",
    "        \n",
    "        # Sample rows\n",
    "        print(\"\\nSample Data (first 3 rows):\")\n",
    "        for i, row in enumerate(rows[:3]):\n",
    "            print(f\"  Row {i+1}: {dict(zip(headers, row))}\")\n",
    "        \n",
    "        return {\n",
    "            'filename': os.path.basename(file_path),\n",
    "            'shape': (total_rows, num_cols),\n",
    "            'columns': headers,\n",
    "            'column_stats': column_stats,\n",
    "            'business_columns': dict(identified_cols),\n",
    "            'completeness': overall_completeness,\n",
    "            'quality_issues': {\n",
    "                'high_missing': high_missing,\n",
    "                'moderate_missing': moderate_missing\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Analyze all your datasets\n",
    "dataset_analyses = {}\n",
    "\n",
    "# List your available datasets\n",
    "datasets_to_analyze = [\n",
    "    \"/app/data/raw/kaggle_datasets/brazilian-ecommerce/olist_customers_dataset.csv\",\n",
    "    \"/app/data/raw/kaggle_datasets/brazilian-ecommerce/olist_products_dataset.csv\",\n",
    "    \"/app/data/raw/kaggle_datasets/brazilian-ecommerce/olist_orders_dataset.csv\",\n",
    "    \"/app/data/raw/kaggle_datasets/brazilian-ecommerce/olist_order_items_dataset.csv\",\n",
    "    \"/app/data/raw/kaggle_datasets/brazilian-ecommerce/olist_order_payments_dataset.csv\",\n",
    "    \"/app/data/raw/kaggle_datasets/brazilian-ecommerce/olist_order_reviews_dataset.csv\"\n",
    "]\n",
    "\n",
    "print(\"COMPREHENSIVE DATA EXPLORATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for dataset_path in datasets_to_analyze:\n",
    "    if os.path.exists(dataset_path):\n",
    "        analysis = comprehensive_csv_analysis(dataset_path, sample_size=1000)\n",
    "        if analysis:\n",
    "            dataset_analyses[analysis['filename']] = analysis\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    else:\n",
    "        print(f\"Dataset not found: {dataset_path}\")\n",
    "\n",
    "# Cross-dataset analysis\n",
    "if dataset_analyses:\n",
    "    print(\"CROSS-DATASET SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"Dataset Overview:\")\n",
    "    for name, analysis in dataset_analyses.items():\n",
    "        print(f\"  {name}: {analysis['shape']} - {analysis['completeness']:.1f}% complete\")\n",
    "    \n",
    "    # Find common columns\n",
    "    all_columns = {}\n",
    "    for name, analysis in dataset_analyses.items():\n",
    "        for col in analysis['columns']:\n",
    "            if col not in all_columns:\n",
    "                all_columns[col] = []\n",
    "            all_columns[col].append(name)\n",
    "    \n",
    "    common_cols = {col: files for col, files in all_columns.items() if len(files) > 1}\n",
    "    if common_cols:\n",
    "        print(\"\\nCommon columns across datasets:\")\n",
    "        for col, files in common_cols.items():\n",
    "            print(f\"  {col}: {files}\")\n",
    "    \n",
    "    # Business use case assessment\n",
    "    print(\"\\nBusiness Use Case Assessment:\")\n",
    "    \n",
    "    use_cases = {\n",
    "        'Sales Forecasting': ['date', 'sales', 'amount', 'price', 'quantity', 'order'],\n",
    "        'Customer Analysis': ['customer', 'user', 'buyer', 'purchase', 'order'],\n",
    "        'Product Analytics': ['product', 'item', 'category', 'price', 'rating'],\n",
    "        'Transaction Analysis': ['order', 'payment', 'amount', 'date', 'customer']\n",
    "    }\n",
    "    \n",
    "    for use_case, required_keywords in use_cases.items():\n",
    "        suitable_datasets = []\n",
    "        for name, analysis in dataset_analyses.items():\n",
    "            col_text = ' '.join(analysis['columns']).lower()\n",
    "            matches = sum(1 for keyword in required_keywords if keyword in col_text)\n",
    "            if matches >= 2:  # At least 2 matching keywords\n",
    "                suitable_datasets.append((name, matches))\n",
    "        \n",
    "        print(f\"\\n{use_case}:\")\n",
    "        if suitable_datasets:\n",
    "            for dataset, match_count in sorted(suitable_datasets, key=lambda x: x[1], reverse=True):\n",
    "                print(f\"  {dataset}: {match_count}/{len(required_keywords)} keyword matches\")\n",
    "        else:\n",
    "            print(\"  No suitable datasets found\")\n",
    "\n",
    "print(\"\\nNext Steps Recommendations:\")\n",
    "print(\"1. Focus on datasets with >80% completeness for initial development\")\n",
    "print(\"2. Plan data joining strategy using common columns\")\n",
    "print(\"3. Prioritize use cases based on data availability\")\n",
    "print(\"4. Design cleaning pipeline for identified quality issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2825b-076d-49ba-a56d-8f181a041a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
