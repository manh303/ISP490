services:
  # ====================================
  # CORE DATABASES
  # ====================================
  # PostgreSQL Database
  postgres:
    build: 
      context: ./database/docker/postgres
      dockerfile: Dockerfile
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./data/backups:/backups
    ports:
      - "5432:5432"
    networks:
      - dss_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 30s
      timeout: 5s
      retries: 5

  # MongoDB Database
  mongodb:
    build:
      context: ./database/docker/mongodb
      dockerfile: Dockerfile
    environment:
      MONGO_INITDB_DATABASE: ${MONGO_DB}
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
    volumes:
      - mongo_data:/data/db
      - ./data/mongo_backups:/backups
    ports:
      - "27017:27017"
    networks:
      - dss_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 5s
      retries: 5

  # ====================================
  # KAFKA STREAMING CLUSTER
  # ====================================
  zookeeper:
    build:
      context: ./deployment/zookeeper
      dockerfile: Dockerfile
    hostname: zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INITLIMIT: 5
      ZOOKEEPER_SYNCLIMIT: 2
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    ports:
      - "2181:2181"
    networks:
      - dss_network
    healthcheck:
      test: ["CMD-SHELL", "echo 'ruok' | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    build:
      context: ./deployment/kafka
      dockerfile: Dockerfile
    hostname: kafka
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9997:9997"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_JMX_PORT: 9997
      KAFKA_JMX_HOSTNAME: localhost
    volumes:
      - kafka_data:/var/lib/kafka/data
      - ./streaming/kafka-jobs:/app/kafka-jobs
    networks:
      - dss_network
    healthcheck:
      test: ["CMD", "/usr/local/bin/healthcheck.sh"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka UI for monitoring
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8090:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - dss_network

  # ====================================
  # SPARK CLUSTER FOR STREAM PROCESSING
  # ====================================
  spark-master:
    build:
      context: ./deployment/spark
      dockerfile: Dockerfile
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
    ports:
      - "7077:7077"   # Spark Master
      - "8081:8080"   # Spark Master WebUI
      - "4040:4040"   # Spark Application UI
    volumes:
      - ./data:/app/data
      - ./streaming/spark-jobs:/app/streaming
      - spark_logs:/app/logs
      - spark_checkpoints:/app/checkpoints
    networks:
      - dss_network
    healthcheck:
      test: ["CMD", "/usr/local/bin/healthcheck.sh"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  spark-worker-1:
    build:
      context: ./deployment/spark
      dockerfile: Dockerfile
    container_name: spark-worker-1
    hostname: spark-worker-1
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
    ports:
      - "8082:8081"   # Worker WebUI
    volumes:
      - ./data:/app/data
      - ./streaming/spark-jobs:/app/streaming
      - spark_logs:/app/logs
      - spark_checkpoints:/app/checkpoints
    networks:
      - dss_network
    restart: unless-stopped

  spark-worker-2:
    build:
      context: ./deployment/spark
      dockerfile: Dockerfile
    container_name: spark-worker-2
    hostname: spark-worker-2
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
    ports:
      - "8083:8081"   # Worker WebUI
    volumes:
      - ./data:/app/data
      - ./streaming/spark-jobs:/app/streaming
      - spark_logs:/app/logs
      - spark_checkpoints:/app/checkpoints
    networks:
      - dss_network
    restart: unless-stopped

  # Spark History Server
  spark-history:
    build:
      context: ./deployment/spark
      dockerfile: Dockerfile
    container_name: spark-history
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=history-server
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/app/logs
    ports:
      - "18080:18080"  # History Server UI
    volumes:
      - spark_logs:/app/logs
    networks:
      - dss_network
    command: ["/opt/bitnami/spark/sbin/start-history-server.sh"]

  # ====================================
  # REDIS FOR CACHING & SESSIONS
  # ====================================
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - dss_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ====================================
  # AIRFLOW ORCHESTRATION
  # ====================================
  # Airflow Database
  airflow-db:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_db_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - dss_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Airflow Init (run once to setup DB)
  airflow-init:
    build: ./airflow
    environment: &airflow-common-env
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@airflow-db/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      AIRFLOW_CONN_POSTGRES_DEFAULT: postgres://dss_user:dss_password_123@postgres:5432/ecommerce_dss
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
      - ./data:/app/data
      - ./data-pipeline/src:/app/src
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db init &&
        airflow users create \
          --username admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com \
          --password admin123
    depends_on:
      airflow-db:
        condition: service_healthy
    networks:
      - dss_network

  # Airflow Webserver
  airflow-webserver:
    build: ./airflow
    command: webserver
    ports:
      - "8080:8080"
    environment:
      <<: *airflow-common-env
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
      - ./data:/app/data
      - ./data-pipeline/src:/app/src
    depends_on:
      - airflow-init
    restart: unless-stopped
    networks:
      - dss_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Airflow Scheduler
  airflow-scheduler:
    build: ./airflow
    command: scheduler
    environment:
      <<: *airflow-common-env
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
      - ./data:/app/data
      - ./data-pipeline/src:/app/src
    depends_on:
      - airflow-init
    restart: unless-stopped
    networks:
      - dss_network

  # Airflow Worker
  airflow-worker:
    build: ./airflow
    command: celery worker
    environment:
      <<: *airflow-common-env
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
      - ./data:/app/data
      - ./data-pipeline/src:/app/src
    depends_on:
      - airflow-init
    restart: unless-stopped
    networks:
      - dss_network

  # ====================================
  # APPLICATION SERVICES
  # ====================================
  # Data Pipeline Service
  data-pipeline:
    build:
      context: ./data-pipeline
      dockerfile: Dockerfile
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - MONGO_HOST=mongodb
      - MONGO_PORT=27017
      - MONGO_DB=${MONGO_DB}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAGGLE_USERNAME=${KAGGLE_USERNAME}
      - KAGGLE_KEY=${KAGGLE_KEY}
    volumes:
      - ./data:/app/data
      - ./data-pipeline/logs:/app/logs
      - ./data-pipeline:/app  # Mount source code for development
    ports:
      - "8888:8888"  # Jupyter/Development port
    depends_on:
      postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    networks:
      - dss_network
    restart: unless-stopped
    command: ["tail", "-f", "/dev/null"]  # Keep container alive

  # Backend API Service
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      # Database Configuration
      - DATABASE_URL=postgresql+asyncpg://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      - MONGODB_URL=mongodb://${MONGO_ROOT_USER}:${MONGO_ROOT_PASSWORD}@mongodb:27017/
      - REDIS_URL=redis://redis:6379
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - MONGO_HOST=mongodb
      - MONGO_PORT=27017
      - MONGO_DB=${MONGO_DB}
      - MONGO_ROOT_USER=${MONGO_ROOT_USER}
      - MONGO_ROOT_PASSWORD=${MONGO_ROOT_PASSWORD}
      - REDIS_HOST=redis
      - REDIS_PORT=6379

      # Kafka Configuration
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_SERVERS=kafka:29092

      # Security Configuration
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - SECRET_KEY=${SECRET_KEY}
      - ACCESS_TOKEN_EXPIRE_MINUTES=30

      # Performance Configuration
      - CACHE_ENABLED=true
      - CACHE_TTL=300
      - RATE_LIMIT_ENABLED=true
      - RATE_LIMIT_REQUESTS=100
      - RATE_LIMIT_WINDOW=60

      # Application Configuration
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=INFO
      - API_V1_PREFIX=/api/v1
      - PROJECT_NAME=E-commerce DSS API
      - VERSION=2.0.0

      # ML Configuration
      - MODELS_PATH=/app/models

      # Monitoring
      - PROMETHEUS_ENABLED=true
      - GRAFANA_ENABLED=true

      # Features
      - ENABLE_CORS=true
      - ENABLE_GZIP=true
      - ENABLE_SECURITY_HEADERS=true

      # Pool Settings
      - MAX_CONNECTIONS_COUNT=10
      - MIN_CONNECTIONS_COUNT=1
    ports:
      - "8000:8000"
    volumes:
      - ./data/models:/app/models
    depends_on:
      postgres:
        condition: service_healthy
      data-pipeline:
        condition: service_started
    networks:
      - dss_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 5s
      retries: 5

  # Frontend Service
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - REACT_APP_API_URL=http://localhost/api
      - REACT_APP_WS_URL=ws://localhost/ws
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - dss_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 5s
      retries: 5

  # ====================================
  # MONITORING & OBSERVABILITY
  # ====================================
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml
      - prometheus_data:/prometheus
    networks:
      - dss_network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    restart: unless-stopped

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    networks:
      - dss_network
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    restart: unless-stopped

  # PostgreSQL Exporter
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    ports:
      - "9187:9187"
    environment:
      - DATA_SOURCE_NAME=postgresql://dss_user:dss_password_123@postgres:5432/ecommerce_dss?sslmode=disable
    networks:
      - dss_network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped

  # Redis Exporter
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://redis:6379
    networks:
      - dss_network
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

  # MongoDB Exporter
  mongodb-exporter:
    image: percona/mongodb_exporter:latest
    container_name: mongodb-exporter
    ports:
      - "9216:9216"
    environment:
      - MONGODB_URI=mongodb://admin:admin_password@mongodb:27017
    networks:
      - dss_network
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - dss_network
    depends_on:
      - prometheus

  # ====================================
  # LOAD BALANCER
  # ====================================
  # Nginx Reverse Proxy
  nginx:
    build:
      context: ./deployment/nginx
      dockerfile: Dockerfile
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      frontend:
        condition: service_healthy
      backend:
        condition: service_healthy
    networks:
      - dss_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 5s
      retries: 5

volumes:
  # Database volumes
  postgres_data:
    driver: local
  mongo_data:
    driver: local
  redis_data:
    driver: local
  airflow_db_data:
    driver: local

  # Streaming volumes
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  
  # Spark volumes
  spark_logs:
    driver: local
  spark_checkpoints:
    driver: local

  # Monitoring volumes
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  dss_network:
    driver: bridge